from pyspark import SparkContext, SQLContext
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Initialize SparkSession
spark = SparkSession.builder \
    .appName("DataProcessingRoutine") \
    .config("spark.jars.packages", "org.mongodb.spark:mongo-spark-connector_2.12:3.0.1") \
    .getOrCreate()

# MongoDB connection details
mongo_username = "demo1"
mongo_password = "demo1"
mongo_cluster = "cluster0.0vgxldr.mongodb.net"
mongo_database = "test"

# Construct MongoDB URI
users_ip = f"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_cluster}/{mongo_database}.users?retryWrites=true&w=majority"
policies_ip = f"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_cluster}/{mongo_database}.policies?retryWrites=true&w=majority"
claims_ip = f"mongodb+srv://{mongo_username}:{mongo_password}@{mongo_cluster}/{mongo_database}.claims?retryWrites=true&w=majority"

# Load data from MongoDB with the specified collection name
users = spark.read.format("com.mongodb.spark.sql.DefaultSource").option("uri", users_ip).load()
policies = spark.read.format("com.mongodb.spark.sql.DefaultSource").option("uri", policies_ip).load()
claims = spark.read.format("com.mongodb.spark.sql.DefaultSource").option("uri", claims_ip).load()

# Create a temporary view
users.createOrReplaceTempView("users")
policies.createOrReplaceTempView("policies")
claims.createOrReplaceTempView("claims")


# Define SQL queries for data quality checks
queries = [
    ("User Details if any user's name contain any digits", "SELECT * FROM users WHERE name REGEXP '[0-9]'"),
    ("Policies where policyType contain any digits", "SELECT * FROM policies WHERE policyType REGEXP '[0-9]'"),
    ("Count of Null Claimed Amounts in Claims", "SELECT COUNT(*) AS NullClaimedAmountCount FROM claims WHERE amount IS NULL")
]

# Execute queries and display results
for query_name, query_sql in queries:
    query_df = spark.sql(query_sql)
    print(query_name)
    query_df.show()

# Stop SparkSession
spark.stop()



